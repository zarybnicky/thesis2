* (front matter)                                              :ignoreheading:
#+LANGUAGE: en
#+OPTIONS: texht:nil toc:nil author:nil ':t
#+LATEX_CLASS: fitthesis
#+LATEX_CLASS_OPTIONS: [english,zadani,odsaz]
# print = B&W links and logo
# cprint = B&W links, color logo
#+BIND: org-latex-title-command ""
#+BIND: org-latex-default-figure-position "tbh"
#+LATEX_HEADER: \usepackage{minted}
#+LATEX_HEADER: \usepackage{tikz}
#+LATEX_HEADER: \usepackage{tikz-cd}
#+LATEX_HEADER: \usepackage{bussproofs}
#+LaTeX_HEADER: \usepackage[figure,table,listing]{totalcount}
#+LaTeX_HEADER: \input{metadata}
#+BEGIN_EXPORT latex
\maketitle
\setlength{\parskip}{0pt}
{\hypersetup{hidelinks}\tableofcontents}
\iftotalfigures\listoffigures\fi
\iftotaltables\listoftables\fi
\iftotallistings\listoflistings\fi
\iftwoside\cleardoublepage\fi
\setlength{\parskip}{0.5\bigskipamount}
#+END_EXPORT

* Introduction
When creating small experimental or research languages, writing a compiler may
be too much effort for the expected gain. On the other hand an interpreter is
usually not as performant as its creators may require for more computationally
intensive tasks.

There is a potential third way, proposed by Yoshihiko Futamura in the 1970s,
called the Futamura projection (or partial program evaluation), wherein an
interpreter is specialized in conjunction with the source code of a program,
yielding an executable. Some parts of the interpreter may be specialized, some
optimized, some left off entirely. Depending on the quality of the specializer,
the gains may be several orders of magnitude.

The goal of my thesis is to evaluate whether the GraalVM/Truffle platform is
suitable enough to act as a specializer for functional languages, in particular
for the dependently-typed lambda calculus.  To illustrate in Figure
\ref{fig:futamora}, the question is whether the path \textit{Native
Image\textrightarrow Result} is fast enough compared to the path
\textit{Executable\textrightarrow Result}.

#+BEGIN_EXPORT latex
\begin{figure}
\centering
\begin{tikzcd}
{} & Program
 \arrow[ld, "Compiler" description, bend right]
 \arrow[dd, "Interpreter" description, bend right=67]
 \arrow[rd, "Partial\ Evaluation" description, bend left]
 \arrow[dd, "JIT" description, bend left=67] & {} \\
Executable \arrow[rd, "Run" description, bend right] & {} & Native\ Image \arrow[ld, "Run", bend left]
 \\ {} & Result & {}
\end{tikzcd}
\caption{Methods of program execution}
\label{fig:futamora}
\end{figure}
#+END_EXPORT

Truffle has already been used rather successfully for the (mostly) imperative
languages Ruby, Python, R, Java, and WebAssembly, but (purely-)functional
languages differ in their evaluation model and in particular the required
allocation throughput, so it is still an open question whether GraalVM is a good
enough fit.

The desired outcome---at least, of the first part of my thesis---is a set of
implementations, and a set of benchmarks demonstrating a positive or a negative
result.  If the result is positive, there are many potential follow-up tasks:
implementing a different, more complex language, maybe a language to be
interpreted into the dependently-typed lambda calculus to attempt the approach
implemented in the /Collapsing Tower of Interpreters/ \cite{amin2017collapsing},
or experimenting with different runtime models - all depending on the results of
this preliminary proof of concept.

In the best case, the JIT-compiled program would be as close in performance to a
program processed by a hand-crafted compiler as possible (not including JIT
warm-up), and I would spend the second half of my thesis on different topics
(like provably-correct program transformations) instead of hand-optimizing the
primitive operations - I should find out which it is going to be as soon in the
second term as possible.

As far as I am aware, there are no other native just-in-time compiled
implementations of the dependently-typed lambda calculus, with the exception of
the preliminary investigations done by the originator of this idea
\cite{kmett_2019}, although there are a few projects implementing a lambda
calculus directly to the Java Virtual Machine byte code..

* Partial evaluation/JIT/Futamura

* JIT principles

* GraalVM/Truffle
*GraalVM* is a just-in-time optimizing compiler for the Java bytecode. *Truffle* is
a set of libraries that expose the internals of the GraalVM compiler, intended
for easy implementation of other languages. So far JavaScript, Python, Ruby, R,
and WebAssembly have Truffle implementations, and therefore can run on the JVM.

GraalVM is also intended to allow creating /polyglot applications/ easily,
applications that have their parts written in different languages. It is
therefore easy to e.g. call R to create visualizations for the results of a
Python program, or to call any Truffle language from Java.

There is also the option to compile a /Native Image/ to eliminate most program
start-up costs associated with a just-in-time compiler, pre-compiling the
program partially (ahead-of-time).

From the point of view of a programmer, Truffle makes it possible to write an
interpreter, and then slowly add optimizations like program graph rewriting,
node specializations, inline instruction caching or others. This seems like a
good middle ground between spending large amounts of time on an optimized
compiler, and just specifying the semantics of a program in an interpreter that,
however, will likely not run quickly.

While GraalVM/Truffle is open-source and released under GPL v2, an
enterprise edition that claims large performance improvements is released
commercially.

#+ATTR_LaTeX: :placement [!htb]
#+CAPTION: GraalVM and Truffle (source: oracle.com)
[[./img/graalvm.jpg]]

* Dependently-Typed Lambda Calculus
The untyped lambda calculus is introduced in the intermediate programming
languages class but I haven't yet encountered its simply- or dependently-typed
variants during my studies.

The untyped lambda calculus is a simple language consisting of just three kinds
of forms: variables, function application, and abstraction.

#+CAPTION: Untyped lambda calculus
#+ATTR_LaTeX: :options [!htpb]
#+begin_figure latex
\[\begin{array}{ccll}
e & ::= & x            & \text{variable} \\
  & |   & e_1~e_2      & \text{application} \\
  & |   & \lambda x. e & \text{abstraction}
\end{array}\]
#+end_figure

The simply-typed lambda calculus adds a fourth kind of a term, type annotation,
and its type language:

#+CAPTION: Simply typed lambda calculus
#+ATTR_LaTeX: :options [!htpb]
#+begin_figure latex
\[\begin{array}{ccll}
e & ::= & x           & \text{variable} \\
  & |   & e_1~e_2      & \text{application} \\
  & |   & \lambda x. e & \text{abstraction} \\
  & |   & x:\tau     & \text{annotation}
\end{array}\]
\[\begin{array}{ccll}
\tau & ::= & \alpha           & \text{base type} \\
     & |   & \tau\rightarrow\tau' & \text{composite type}
\end{array}\]
#+end_figure

The dependently typed lambda calculus merges these two languages together,
simplifying the grammar.

#+CAPTION: Dependently typed lambda calculus
#+ATTR_LaTeX: :options [!htpb]
#+begin_figure latex
\[\begin{array}{ccll}
e & ::= & x           & \text{variable} \\
  & |   & e_1~e_2      & \text{application} \\
  & |   & \lambda x. e & \text{abstraction} \\
  & |   & x:\tau      & \text{annotation} \\
  & |   & *           & \text{the type of types} \\
  & |   & \forall x:\rho.\rho' & \text{dependent function space}
\end{array}\]
#+end_figure

As I was already familiar with the use of dependent types in general programming
e.g.  in Agda or Idris, I took this opportunity to investigate the theoretical
basis of type systems - type systems in general, as used in general programming
languages, their various limitations---like the need to extend System F (System
FC) as used in Haskell to support fully dependent types
\cite{eisenberg2016dependent}, the lambda cube, the expressive power of
different kinds of type systems, and where they are used.


* LambdaPi specification

* LambdaPi Interpreter
I have implemented a dependently typed lambda calculus called LambdaPi based on
the prior work /A tutorial implementation of a dependently typed lambda calculus/
\cite{loh2010tutorial}. The parser and interpreter are written in Kotlin, where
I will also need to write the JIT implementation. This is a pure interpreter
that will serve as a baseline for future benchmarks.

#+ATTR_LaTeX: :placement [!htpb]
#+CAPTION: The constant function in LambdaPi
#+begin_src text
let const = (\ a b x y -> x) :: forall (a :: *) (b :: *) . a -> b -> a
#+end_src

* Truffle-based compiler

* LLVM-based compiler

* Benchmarks

* Evaluation

* (bibliography, start of appendix)                           :ignoreheading:
#+BEGIN_EXPORT latex
\makeatletter
\def\@openbib@code{\addcontentsline{toc}{chapter}{Bibliography}}
\makeatother
\bibliographystyle{bibstyle}

\begin{flushleft}
\bibliography{bibliography}
\end{flushleft}
\iftwoside\cleardoublepage\fi

% Appendices
\appendix
\appendixpage
\iftwoside\cleardoublepage\fi

\startcontents[chapters]
% \setlength{\parskip}{0pt}
% \printcontents[chapters]{l}{0}{\setcounter{tocdepth}{2}}
% \setlength{\parskip}{0.5\bigskipamount}
\iftwoside\cleardoublepage\fi
#+END_EXPORT

* Contents of the attached data storage
...
